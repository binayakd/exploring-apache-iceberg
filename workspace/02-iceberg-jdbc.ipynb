{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81e35ec8-0ec2-4845-8584-3d09a67f7a14",
   "metadata": {},
   "source": [
    "# JDBC/SQL Catalog\n",
    "Now we are setting up and testing the JDBC/SQL Catalog. Here we only need the postgres instance that we have already setup, and have used with our Hive Metastore. Just that we are connecting to a separate `iceberg` database in that instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52b4fc3-fbaa-49e4-8694-3bdaf7301101",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "As before we will be importing `SparkSession` for, well, the Spark session, and the Postgress driver `psycopg`, Trino connection libraries, and pandas, to explore the data that we will be writing with Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd659063-16d9-48a3-a217-07d95142fe08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import psycopg\n",
    "from trino.dbapi import connect\n",
    "import pandas as pd\n",
    "\n",
    "# this is to better display pyspark and pandas dataframes\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0d0160-5a87-4caa-bd41-304967249726",
   "metadata": {},
   "source": [
    "## Setting up Spark Session\n",
    "\n",
    "We now setup the Spark session with the configs required to connect to the postgres database, to act as the catalog. This involves adding the postgres JDBC driver that we installed in the docker image in the location `/opt/extra-jars/postgresql.jar` to be added to the `spark.jars` config, in addition to the already added Iceberg related jars. We also have all the needed JDBC connection configs ([details here](https://iceberg.apache.org/docs/1.5.0/jdbc/)) under the catalog `iceberg`. This name will become important as we will see later.\n",
    "\n",
    "Again, to connect to our local instance of Minio, we need to set `s3.endpoint` and `s3.path-style-access` configs, and set our warehouse location to be in the folder `iceberg` under the bucket `warehouse` that was created on startup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cc8f0a6-3666-40d8-a744-48c855ec2c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/13 15:30:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "iceberg_catalog_name = \"iceberg\"\n",
    "spark = SparkSession.builder \\\n",
    "  .appName(\"iceberg-jdbc\") \\\n",
    "  .config(\"spark.driver.memory\", \"4g\") \\\n",
    "  .config(\"spark.executor.memory\", \"4g\") \\\n",
    "  .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "  .config(\"spark.jars\", \"/opt/extra-jars/iceberg-spark-runtime.jar,/opt/extra-jars/iceberg-aws-bundle.jar,/opt/extra-jars/postgresql.jar\") \\\n",
    "  .config(f\"spark.sql.catalog.{iceberg_catalog_name}\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "  .config(f\"spark.sql.catalog.{iceberg_catalog_name}.type\", \"jdbc\") \\\n",
    "  .config(f\"spark.sql.catalog.{iceberg_catalog_name}.uri\", \"jdbc:postgresql://postgres:5432/iceberg\") \\\n",
    "  .config(f\"spark.sql.catalog.{iceberg_catalog_name}.jdbc.user\", \"postgres\") \\\n",
    "  .config(f\"spark.sql.catalog.{iceberg_catalog_name}.jdbc.password\", \"postgres\") \\\n",
    "  .config(f\"spark.sql.catalog.{iceberg_catalog_name}.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\") \\\n",
    "  .config(f\"spark.sql.catalog.{iceberg_catalog_name}.warehouse\", \"s3://warehouse/iceberg/\") \\\n",
    "  .config(f\"spark.sql.catalog.{iceberg_catalog_name}.s3.endpoint\", \"http://minio:9000\") \\\n",
    "  .config(f\"spark.sql.catalog.{iceberg_catalog_name}.s3.path-style-access\", \"true\") \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dd6895-1566-4f86-bfea-97be24429485",
   "metadata": {},
   "source": [
    "## Loading Test Data\n",
    "Now we load the 2 parquet files downloaded previously, into the Spark memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c99538-29f3-4115-ad6d-f0618188bc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/13 15:31:13 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "df_2024_01 = spark.read.parquet(\"file:///home/iceberg/workspace/downloaded-data/yellow_tripdata_2024-01.parquet\")\n",
    "df_2024_02 = spark.read.parquet(\"file:///home/iceberg/workspace/downloaded-data/yellow_tripdata_2024-02.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a48b2ac-769c-4170-b032-480ad35f3bb7",
   "metadata": {},
   "source": [
    "## Creating namespace under the catalog\n",
    "Now we created the namespace`jdbc`. We won't set any location, as we have already set a default warehouse location for this catalog when creating the Spark session. So it should create a folder under that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42629e00-75d1-4d33-ac35-8cc6952071a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS iceberg.jdbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e71ef43-24b8-4c99-991f-8e4a880ecb76",
   "metadata": {},
   "source": [
    "## Writing the data to Iceberg Table\n",
    "Again as before, we crate the table first, based on 2024-01 data, partitioned by the month, deriving it from the `tpep_pickup_datetime` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63d5f0a-4979-43b2-88e3-bcbedbdae3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_2024_01.writeTo(\"iceberg.jdbc.yellow_tripdata\").partitionedBy(\n",
    "    F.months(\"tpep_pickup_datetime\")\n",
    ").create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21605d5-24c7-4153-9776-acca0701fe36",
   "metadata": {},
   "source": [
    "Checking the data saved to Minio, where we expect it to be, under `iceberg/jdbc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c69f291a-afda-4c19-9fa4-68e2354456c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]11;?\u001b\\\u001b[6n\u001b[m\u001b[32m[2024-09-11 16:10:05 UTC]\u001b[0m\u001b[33m 5.9KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/data/tpep_pickup_datetime_month=2002-12/00000-10-c34f04bf-cde6-4327-a36b-fc50f8b957b9-0-00003.parquet\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-11 16:10:05 UTC]\u001b[0m\u001b[33m 5.9KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/data/tpep_pickup_datetime_month=2009-01/00000-10-c34f04bf-cde6-4327-a36b-fc50f8b957b9-0-00004.parquet\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-11 16:10:05 UTC]\u001b[0m\u001b[33m 6.3KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/data/tpep_pickup_datetime_month=2023-12/00000-10-c34f04bf-cde6-4327-a36b-fc50f8b957b9-0-00001.parquet\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-11 16:10:05 UTC]\u001b[0m\u001b[33m  44MiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/data/tpep_pickup_datetime_month=2024-01/00000-10-c34f04bf-cde6-4327-a36b-fc50f8b957b9-0-00002.parquet\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-11 16:10:05 UTC]\u001b[0m\u001b[33m 5.9KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/data/tpep_pickup_datetime_month=2024-02/00000-10-c34f04bf-cde6-4327-a36b-fc50f8b957b9-0-00005.parquet\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-11 16:10:06 UTC]\u001b[0m\u001b[33m 3.8KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/metadata/00000-fdb3dbc7-7f1c-419f-8062-f592a05e7e98.metadata.json\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-11 16:10:06 UTC]\u001b[0m\u001b[33m 9.0KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/metadata/fe6f97c1-805d-46b3-b83a-80a882c19029-m0.avro\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-11 16:10:06 UTC]\u001b[0m\u001b[33m 4.1KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/metadata/snap-4307659518017302486-1-fe6f97c1-805d-46b3-b83a-80a882c19029.avro\u001b[22m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!mc ls --recursive minio/warehouse/iceberg/jdbc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5aaf5f-fc7f-46e7-ae7e-7e99b3208b1c",
   "metadata": {},
   "source": [
    "And, as expected, we do see the same data in partitions, and the metadata file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda8008e",
   "metadata": {},
   "source": [
    "Now we also check what metadata has been written database. Using the `psycopg` and `pandas` library, can get the data from specific tables in the Postgres database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c307b4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg.connect(\"postgresql://postgres:postgres@postgres:5432/iceberg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8f33b0",
   "metadata": {},
   "source": [
    "There are actually only 2 tables that were created and written to: `iceberg_namespace_properties` and `iceberg_tables`. First we check the `iceberg_namespace_properties` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1045ae58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8/2890180982.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pd.read_sql_query('select * from iceberg_namespace_properties', conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog_name</th>\n",
       "      <th>namespace</th>\n",
       "      <th>property_key</th>\n",
       "      <th>property_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iceberg</td>\n",
       "      <td>jdbc</td>\n",
       "      <td>owner</td>\n",
       "      <td>iceberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iceberg</td>\n",
       "      <td>jdbc</td>\n",
       "      <td>exists</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  catalog_name namespace property_key property_value\n",
       "0      iceberg      jdbc        owner        iceberg\n",
       "1      iceberg      jdbc       exists           true"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query('select * from iceberg_namespace_properties', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09273621",
   "metadata": {},
   "source": [
    "We see 2 properties for the `iceberg` catalog and `jdbc` namespace. The name `iceberg` is gotten from the catalog name we set when creating the Spark session. \n",
    "\n",
    "Now we check the table `iceberg_tables`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8b6b631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8/88100972.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pd.read_sql_query('select * from iceberg_tables', conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog_name</th>\n",
       "      <th>table_namespace</th>\n",
       "      <th>table_name</th>\n",
       "      <th>metadata_location</th>\n",
       "      <th>previous_metadata_location</th>\n",
       "      <th>iceberg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iceberg</td>\n",
       "      <td>jdbc</td>\n",
       "      <td>yellow_tripdata</td>\n",
       "      <td>s3://warehouse/iceberg/jdbc/yellow_tripdata/me...</td>\n",
       "      <td>None</td>\n",
       "      <td>TABLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  catalog_name table_namespace       table_name  \\\n",
       "0      iceberg            jdbc  yellow_tripdata   \n",
       "\n",
       "                                   metadata_location  \\\n",
       "0  s3://warehouse/iceberg/jdbc/yellow_tripdata/me...   \n",
       "\n",
       "  previous_metadata_location iceberg_type  \n",
       "0                       None        TABLE  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query('select * from iceberg_tables', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f427913",
   "metadata": {},
   "source": [
    "Here we see a single entry, giving information about the metadata file location in Minio, for the table we just created. Compared to the information in the Hive catalog, this is a lot more bare bone, acting more like a pointer to the actual location of the metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd0a699",
   "metadata": {},
   "source": [
    "## Adding New partition to the table\n",
    "Now, as before, we will add the file for the month of 2024-02 as a new partition to the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99229c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_2024_02.writeTo(\"iceberg.jdbc.yellow_tripdata\").append()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d73b6c",
   "metadata": {},
   "source": [
    "Checking on the data in Minio, we see the new partitions, and metadata files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0de59e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]11;?\u001b\\\u001b[6n\u001b[m\u001b[32m[2024-09-11 16:10:05 UTC]\u001b[0m\u001b[33m 5.9KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/data/tpep_pickup_datetime_month=2002-12/00000-10-c34f04bf-cde6-4327-a36b-fc50f8b957b9-0-00003.parquet\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-13 16:02:22 UTC]\u001b[0m\u001b[33m 5.3KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/data/tpep_pickup_datetime_month=2008-12/00000-10-193c7271-9ebc-4616-a74d-dd220caf32a5-0-00003.parquet\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-13 16:02:22 UTC]\u001b[0m\u001b[33m 5.3KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/data/tpep_pickup_datetime_month=2009-01/00000-10-193c7271-9ebc-4616-a74d-dd220caf32a5-0-00004.parquet\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-11 16:10:05 UTC]\u001b[0m\u001b[33m 5.9KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/data/tpep_pickup_datetime_month=2009-01/00000-10-c34f04bf-cde6-4327-a36b-fc50f8b957b9-0-00004.parquet\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-11 16:10:05 UTC]\u001b[0m\u001b[33m 6.3KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/data/tpep_pickup_datetime_month=2023-12/00000-10-c34f04bf-cde6-4327-a36b-fc50f8b957b9-0-00001.parquet\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-13 16:02:21 UTC]\u001b[0m\u001b[33m 6.3KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/data/tpep_pickup_datetime_month=2024-01/00000-10-193c7271-9ebc-4616-a74d-dd220caf32a5-0-00001.parquet\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-11 16:10:05 UTC]\u001b[0m\u001b[33m  44MiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/data/tpep_pickup_datetime_month=2024-01/00000-10-c34f04bf-cde6-4327-a36b-fc50f8b957b9-0-00002.parquet\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-13 16:02:22 UTC]\u001b[0m\u001b[33m  44MiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/data/tpep_pickup_datetime_month=2024-02/00000-10-193c7271-9ebc-4616-a74d-dd220caf32a5-0-00002.parquet\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-11 16:10:05 UTC]\u001b[0m\u001b[33m 5.9KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/data/tpep_pickup_datetime_month=2024-02/00000-10-c34f04bf-cde6-4327-a36b-fc50f8b957b9-0-00005.parquet\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-13 16:02:22 UTC]\u001b[0m\u001b[33m 5.8KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/data/tpep_pickup_datetime_month=2024-03/00000-10-193c7271-9ebc-4616-a74d-dd220caf32a5-0-00005.parquet\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-11 16:10:06 UTC]\u001b[0m\u001b[33m 3.8KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/metadata/00000-fdb3dbc7-7f1c-419f-8062-f592a05e7e98.metadata.json\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-13 16:02:23 UTC]\u001b[0m\u001b[33m 4.9KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/metadata/00001-983875cf-5160-4cfe-a73e-f8d34495bb74.metadata.json\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-13 16:02:23 UTC]\u001b[0m\u001b[33m 8.9KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/metadata/23ab986b-8d26-4cf7-8908-266922ec7e65-m0.avro\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-11 16:10:06 UTC]\u001b[0m\u001b[33m 9.0KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/metadata/fe6f97c1-805d-46b3-b83a-80a882c19029-m0.avro\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-13 16:02:23 UTC]\u001b[0m\u001b[33m 4.2KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/metadata/snap-2752971245912516800-1-23ab986b-8d26-4cf7-8908-266922ec7e65.avro\u001b[22m\u001b[m\n",
      "\u001b[m\u001b[32m[2024-09-11 16:10:06 UTC]\u001b[0m\u001b[33m 4.1KiB\u001b[0m \u001b[34mSTANDARD\u001b[0m\u001b[1m yellow_tripdata/metadata/snap-4307659518017302486-1-fe6f97c1-805d-46b3-b83a-80a882c19029.avro\u001b[22m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!mc ls --recursive minio/warehouse/iceberg/jdbc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac0a31d",
   "metadata": {},
   "source": [
    "Checking the `iceberg_table` table in postgres, we see the `metadata_location` is updated to point to the new json file, and the  `previous_metadata_location` has been set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d15cc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8/88100972.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pd.read_sql_query('select * from iceberg_tables', conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog_name</th>\n",
       "      <th>table_namespace</th>\n",
       "      <th>table_name</th>\n",
       "      <th>metadata_location</th>\n",
       "      <th>previous_metadata_location</th>\n",
       "      <th>iceberg_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iceberg</td>\n",
       "      <td>jdbc</td>\n",
       "      <td>yellow_tripdata</td>\n",
       "      <td>s3://warehouse/iceberg/jdbc/yellow_tripdata/metadata/00001-983875cf-5160-4cfe-a73e-f8d34495bb74.metadata.json</td>\n",
       "      <td>s3://warehouse/iceberg/jdbc/yellow_tripdata/metadata/00000-fdb3dbc7-7f1c-419f-8062-f592a05e7e98.metadata.json</td>\n",
       "      <td>TABLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  catalog_name table_namespace       table_name  \\\n",
       "0      iceberg            jdbc  yellow_tripdata   \n",
       "\n",
       "                                                                                               metadata_location  \\\n",
       "0  s3://warehouse/iceberg/jdbc/yellow_tripdata/metadata/00001-983875cf-5160-4cfe-a73e-f8d34495bb74.metadata.json   \n",
       "\n",
       "                                                                                      previous_metadata_location  \\\n",
       "0  s3://warehouse/iceberg/jdbc/yellow_tripdata/metadata/00000-fdb3dbc7-7f1c-419f-8062-f592a05e7e98.metadata.json   \n",
       "\n",
       "  iceberg_type  \n",
       "0        TABLE  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query('select * from iceberg_tables', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29c555d-370a-485c-aa5d-a6dd799021e3",
   "metadata": {},
   "source": [
    "## Querying with Trino\n",
    "The configurations required to enable Trino queryring would be the [JDBC Catalog configs](https://trino.io/docs/current/object-storage/metastores.html#iceberg-jdbc-catalog), which have been setup in our Trino deployment:\n",
    "\n",
    "```\n",
    "connector.name=iceberg\n",
    "iceberg.catalog.type=jdbc\n",
    "iceberg.jdbc-catalog.catalog-name=iceberg\n",
    "iceberg.jdbc-catalog.driver-class=org.postgresql.Driver\n",
    "iceberg.jdbc-catalog.connection-url=jdbc:postgresql://postgres:5432/iceberg\n",
    "iceberg.jdbc-catalog.connection-user=postgres\n",
    "iceberg.jdbc-catalog.connection-password=postgres\n",
    "iceberg.jdbc-catalog.default-warehouse-dir=s3://warehouse/iceberg-jdbc/\n",
    "fs.native-s3.enabled=true\n",
    "s3.endpoint=http://minio:9000\n",
    "s3.path-style-access=true\n",
    "s3.aws-access-key=${ENV:AWS_ACCESS_KEY_ID}\n",
    "s3.aws-secret-key=${ENV:AWS_SECRET_ACCESS_KEY}\n",
    "s3.region=${ENV:AWS_REGION}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6722d646-4655-47c9-9c9f-63e065fe9cd6",
   "metadata": {},
   "source": [
    "As before, we setup the Trino python client and run the queries, and load them into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7efd483-dee9-444f-a349-5e0965f978c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trino_conn = connect(\n",
    "    host=\"trino\",\n",
    "    port=8080,\n",
    "    user=\"user\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb2695b1-f6fc-4369-9c41-73e447a8671b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8/129233609.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pd.read_sql_query('select * from \"iceberg-jdbc\".jdbc.yellow_tripdata limit 10', trino_conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendorid</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>ratecodeid</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>pulocationid</th>\n",
       "      <th>dolocationid</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-01 00:57:55</td>\n",
       "      <td>2024-01-01 01:17:43</td>\n",
       "      <td>1</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>17.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.70</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:03:00</td>\n",
       "      <td>2024-01-01 00:09:36</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>140</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:17:06</td>\n",
       "      <td>2024-01-01 00:35:01</td>\n",
       "      <td>1</td>\n",
       "      <td>4.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>23.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:36:38</td>\n",
       "      <td>2024-01-01 00:44:56</td>\n",
       "      <td>1</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:46:51</td>\n",
       "      <td>2024-01-01 00:52:57</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>211</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.10</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:54:08</td>\n",
       "      <td>2024-01-01 01:26:31</td>\n",
       "      <td>1</td>\n",
       "      <td>4.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>148</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>29.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.50</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-01 00:49:44</td>\n",
       "      <td>2024-01-01 01:15:47</td>\n",
       "      <td>2</td>\n",
       "      <td>10.82</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>45.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:30:40</td>\n",
       "      <td>2024-01-01 00:58:40</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>246</td>\n",
       "      <td>231</td>\n",
       "      <td>2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.40</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-01 00:26:01</td>\n",
       "      <td>2024-01-01 00:54:12</td>\n",
       "      <td>1</td>\n",
       "      <td>5.44</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>161</td>\n",
       "      <td>261</td>\n",
       "      <td>2</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-01 00:28:08</td>\n",
       "      <td>2024-01-01 00:29:16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendorid tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2024-01-01 00:57:55   2024-01-01 01:17:43                1   \n",
       "1         1  2024-01-01 00:03:00   2024-01-01 00:09:36                1   \n",
       "2         1  2024-01-01 00:17:06   2024-01-01 00:35:01                1   \n",
       "3         1  2024-01-01 00:36:38   2024-01-01 00:44:56                1   \n",
       "4         1  2024-01-01 00:46:51   2024-01-01 00:52:57                1   \n",
       "5         1  2024-01-01 00:54:08   2024-01-01 01:26:31                1   \n",
       "6         2  2024-01-01 00:49:44   2024-01-01 01:15:47                2   \n",
       "7         1  2024-01-01 00:30:40   2024-01-01 00:58:40                0   \n",
       "8         2  2024-01-01 00:26:01   2024-01-01 00:54:12                1   \n",
       "9         2  2024-01-01 00:28:08   2024-01-01 00:29:16                1   \n",
       "\n",
       "   trip_distance  ratecodeid store_and_fwd_flag  pulocationid  dolocationid  \\\n",
       "0           1.72           1                  N           186            79   \n",
       "1           1.80           1                  N           140           236   \n",
       "2           4.70           1                  N           236            79   \n",
       "3           1.40           1                  N            79           211   \n",
       "4           0.80           1                  N           211           148   \n",
       "5           4.70           1                  N           148           141   \n",
       "6          10.82           1                  N           138           181   \n",
       "7           3.00           1                  N           246           231   \n",
       "8           5.44           1                  N           161           261   \n",
       "9           0.04           1                  N           113           113   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2         17.7    1.0      0.5        0.00           0.0   \n",
       "1             1         10.0    3.5      0.5        3.75           0.0   \n",
       "2             1         23.3    3.5      0.5        3.00           0.0   \n",
       "3             1         10.0    3.5      0.5        2.00           0.0   \n",
       "4             1          7.9    3.5      0.5        3.20           0.0   \n",
       "5             1         29.6    3.5      0.5        6.90           0.0   \n",
       "6             1         45.7    6.0      0.5       10.00           0.0   \n",
       "7             2         25.4    3.5      0.5        0.00           0.0   \n",
       "8             2         31.0    1.0      0.5        0.00           0.0   \n",
       "9             2          3.0    1.0      0.5        0.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                    1.0         22.70                   2.5         0.00  \n",
       "1                    1.0         18.75                   2.5         0.00  \n",
       "2                    1.0         31.30                   2.5         0.00  \n",
       "3                    1.0         17.00                   2.5         0.00  \n",
       "4                    1.0         16.10                   2.5         0.00  \n",
       "5                    1.0         41.50                   2.5         0.00  \n",
       "6                    1.0         64.95                   0.0         1.75  \n",
       "7                    1.0         30.40                   2.5         0.00  \n",
       "8                    1.0         36.00                   2.5         0.00  \n",
       "9                    1.0          8.00                   2.5         0.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query('select * from \"iceberg-jdbc\".jdbc.yellow_tripdata limit 10', trino_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb68850",
   "metadata": {},
   "source": [
    "And as with the Hive Catalog, we can also query the Iceberg metadata (snapshots and partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "289e8f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8/3423483695.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pd.read_sql_query('select * from \"iceberg-jdbc\".jdbc.\"yellow_tripdata$snapshots\"', trino_conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>committed_at</th>\n",
       "      <th>snapshot_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>operation</th>\n",
       "      <th>manifest_list</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-09-11 16:10:06.293000+00:00</td>\n",
       "      <td>4307659518017302486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>append</td>\n",
       "      <td>s3://warehouse/iceberg/jdbc/yellow_tripdata/metadata/snap-4307659518017302486-1-fe6f97c1-805d-46...</td>\n",
       "      <td>{'spark.app.id': 'local-1726070250816', 'changed-partition-count': '5', 'added-data-files': '5',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-09-13 16:02:23.872000+00:00</td>\n",
       "      <td>2752971245912516800</td>\n",
       "      <td>4.307660e+18</td>\n",
       "      <td>append</td>\n",
       "      <td>s3://warehouse/iceberg/jdbc/yellow_tripdata/metadata/snap-2752971245912516800-1-23ab986b-8d26-4c...</td>\n",
       "      <td>{'spark.app.id': 'local-1726241458394', 'changed-partition-count': '5', 'added-data-files': '5',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      committed_at          snapshot_id     parent_id  \\\n",
       "0 2024-09-11 16:10:06.293000+00:00  4307659518017302486           NaN   \n",
       "1 2024-09-13 16:02:23.872000+00:00  2752971245912516800  4.307660e+18   \n",
       "\n",
       "  operation  \\\n",
       "0    append   \n",
       "1    append   \n",
       "\n",
       "                                                                                         manifest_list  \\\n",
       "0  s3://warehouse/iceberg/jdbc/yellow_tripdata/metadata/snap-4307659518017302486-1-fe6f97c1-805d-46...   \n",
       "1  s3://warehouse/iceberg/jdbc/yellow_tripdata/metadata/snap-2752971245912516800-1-23ab986b-8d26-4c...   \n",
       "\n",
       "                                                                                               summary  \n",
       "0  {'spark.app.id': 'local-1726070250816', 'changed-partition-count': '5', 'added-data-files': '5',...  \n",
       "1  {'spark.app.id': 'local-1726241458394', 'changed-partition-count': '5', 'added-data-files': '5',...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.read_sql_query('select * from \"iceberg-jdbc\".jdbc.\"yellow_tripdata$snapshots\"', trino_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d7f9dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8/3297040035.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pd.read_sql_query('select * from \"iceberg-jdbc\".jdbc.\"yellow_tripdata$partitions\"', trino_conn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition</th>\n",
       "      <th>record_count</th>\n",
       "      <th>file_count</th>\n",
       "      <th>total_size</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(tpep_pickup_datetime_month: 467)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5433</td>\n",
       "      <td>(VendorID: (min: 2, max: 2, null_count: 0, nan_count: None), tpep_pickup_datetime: (min: datetim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(tpep_pickup_datetime_month: 468)</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11514</td>\n",
       "      <td>(VendorID: (min: 2, max: 2, null_count: 0, nan_count: None), tpep_pickup_datetime: (min: datetim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(tpep_pickup_datetime_month: 647)</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>6418</td>\n",
       "      <td>(VendorID: (min: 2, max: 2, null_count: 0, nan_count: None), tpep_pickup_datetime: (min: datetim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(tpep_pickup_datetime_month: 648)</td>\n",
       "      <td>2964617</td>\n",
       "      <td>2</td>\n",
       "      <td>46495595</td>\n",
       "      <td>(VendorID: (min: 1, max: 6, null_count: 0, nan_count: None), tpep_pickup_datetime: (min: datetim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(tpep_pickup_datetime_month: 395)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6043</td>\n",
       "      <td>(VendorID: (min: 2, max: 2, null_count: 0, nan_count: None), tpep_pickup_datetime: (min: datetim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(tpep_pickup_datetime_month: 649)</td>\n",
       "      <td>3007514</td>\n",
       "      <td>2</td>\n",
       "      <td>46708043</td>\n",
       "      <td>(VendorID: (min: 1, max: 2, null_count: 0, nan_count: None), tpep_pickup_datetime: (min: datetim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(tpep_pickup_datetime_month: 650)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5908</td>\n",
       "      <td>(VendorID: (min: 2, max: 2, null_count: 0, nan_count: None), tpep_pickup_datetime: (min: datetim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           partition  record_count  file_count  total_size  \\\n",
       "0  (tpep_pickup_datetime_month: 467)             1           1        5433   \n",
       "1  (tpep_pickup_datetime_month: 468)             4           2       11514   \n",
       "2  (tpep_pickup_datetime_month: 647)            10           1        6418   \n",
       "3  (tpep_pickup_datetime_month: 648)       2964617           2    46495595   \n",
       "4  (tpep_pickup_datetime_month: 395)             2           1        6043   \n",
       "5  (tpep_pickup_datetime_month: 649)       3007514           2    46708043   \n",
       "6  (tpep_pickup_datetime_month: 650)             2           1        5908   \n",
       "\n",
       "                                                                                                  data  \n",
       "0  (VendorID: (min: 2, max: 2, null_count: 0, nan_count: None), tpep_pickup_datetime: (min: datetim...  \n",
       "1  (VendorID: (min: 2, max: 2, null_count: 0, nan_count: None), tpep_pickup_datetime: (min: datetim...  \n",
       "2  (VendorID: (min: 2, max: 2, null_count: 0, nan_count: None), tpep_pickup_datetime: (min: datetim...  \n",
       "3  (VendorID: (min: 1, max: 6, null_count: 0, nan_count: None), tpep_pickup_datetime: (min: datetim...  \n",
       "4  (VendorID: (min: 2, max: 2, null_count: 0, nan_count: None), tpep_pickup_datetime: (min: datetim...  \n",
       "5  (VendorID: (min: 1, max: 2, null_count: 0, nan_count: None), tpep_pickup_datetime: (min: datetim...  \n",
       "6  (VendorID: (min: 2, max: 2, null_count: 0, nan_count: None), tpep_pickup_datetime: (min: datetim...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query('select * from \"iceberg-jdbc\".jdbc.\"yellow_tripdata$partitions\"', trino_conn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
