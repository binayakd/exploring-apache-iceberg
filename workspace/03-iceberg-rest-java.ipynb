{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "339829f6-7c19-42cc-8aee-dc99a8ee428e",
   "metadata": {},
   "source": [
    "# Iceberg with Spark and Rest-Java Catalog\n",
    "Here we are using Iceberg with Spark, and using Rest as the Catalog. Here we mostly follow the official Iceberg tutorial, and the provided Rest-Java catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7702f6-38c6-4c01-bc13-c724843631ad",
   "metadata": {},
   "source": [
    "## Importing Required Libraries\n",
    "Importing the same libraries again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6859de9c-3e8d-48a3-8b90-0c83b21a826f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from timeit import default_timer as timer\n",
    "import os\n",
    "\n",
    "# this is to better display pyspark dataframes\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69813517-28cc-4ce5-9c3d-fb70d1d48058",
   "metadata": {},
   "source": [
    "## Setting up Spark Session\n",
    "We set up Spark Session with with the configs required to connect to the Rest Catalog. Here we are setting up `iceberg_rest` as the iceberg catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ac81ff9-719e-4fea-afab-f8b0d03cbe08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/01 08:35:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "iceberg_catalog_name = \"iceberg_rest\"\n",
    "spark = SparkSession.builder \\\n",
    "  .appName(\"iceberg-rest-java\") \\\n",
    "  .config(\"spark.driver.memory\", \"4g\") \\\n",
    "  .config(\"spark.executor.memory\", \"4g\") \\\n",
    "  .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n",
    "  .config(\"spark.jars\", \"/opt/extra-jars/iceberg-spark-runtime.jar,/opt/extra-jars/iceberg-aws-bundle.jar\") \\\n",
    "  .config(f\"spark.sql.catalog.{iceberg_catalog_name}\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n",
    "  .config(f\"spark.sql.catalog.{iceberg_catalog_name}.type\", \"rest\") \\\n",
    "  .config(f\"spark.sql.catalog.{iceberg_catalog_name}.uri\", \"http://iceberg-rest-java:8181\") \\\n",
    "  .config(f\"spark.sql.catalog.{iceberg_catalog_name}.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\") \\\n",
    "  .config(f\"spark.sql.catalog.{iceberg_catalog_name}.warehouse\", \"s3://warehouse/iceberg-rest/\") \\\n",
    "  .config(f\"spark.sql.catalog.{iceberg_catalog_name}.s3.endpoint\", \"http://minio:9000\") \\\n",
    "  .config(f\"spark.sql.catalog.{iceberg_catalog_name}.s3.path-style-access\", \"true\") \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f280199e-411d-471d-a0c2-e2c4a809a1a2",
   "metadata": {},
   "source": [
    "## Setting up the test parquet file as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1753e36a-63f3-46b9-8bc1-8f82626622bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cc_main_df = spark.read.parquet(\"file:///home/iceberg/workspace/downloaded-data/cc-main-2024-06-26-warc-part-00000.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b345fffb-6d13-4a53-af09-708eb60905c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/01 08:35:57 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----------------+------------+----------------------+----------------------+----------------------+----------------------+------------------------+--------------------------+-----------------------+-----------------------+----------------------+------------+--------+--------------------+---------+-------------------+------------+--------------+--------------------+-----------------+---------------------+---------------+-----------------+-----------------+--------------------+------------------+------------------+----------------+\n",
      "|         url_surtkey|                 url|    url_host_name|url_host_tld|url_host_2nd_last_part|url_host_3rd_last_part|url_host_4th_last_part|url_host_5th_last_part|url_host_registry_suffix|url_host_registered_domain|url_host_private_suffix|url_host_private_domain|url_host_name_reversed|url_protocol|url_port|            url_path|url_query|         fetch_time|fetch_status|fetch_redirect|      content_digest|content_mime_type|content_mime_detected|content_charset|content_languages|content_truncated|       warc_filename|warc_record_offset|warc_record_length|    warc_segment|\n",
      "+--------------------+--------------------+-----------------+------------+----------------------+----------------------+----------------------+----------------------+------------------------+--------------------------+-----------------------+-----------------------+----------------------+------------+--------+--------------------+---------+-------------------+------------+--------------+--------------------+-----------------+---------------------+---------------+-----------------+-----------------+--------------------+------------------+------------------+----------------+\n",
      "|ru,vsepostavshiki...|https://vsepostav...|vsepostavshiki.ru|          ru|        vsepostavshiki|                  NULL|                  NULL|                  NULL|                      ru|         vsepostavshiki.ru|                     ru|      vsepostavshiki.ru|     ru.vsepostavshiki|       https|    NULL|/syre/toplivo-ene...|     NULL|2024-06-25 19:29:32|         200|          NULL|NVDY7QVQSDWZAOVW4...|        text/html|            text/html|          UTF-8|          rus,bak|             NULL|crawl-data/CC-MAI...|         522244472|             12096|1718198866218.13|\n",
      "|ru,vsepostavshiki...|https://vsepostav...|vsepostavshiki.ru|          ru|        vsepostavshiki|                  NULL|                  NULL|                  NULL|                      ru|         vsepostavshiki.ru|                     ru|      vsepostavshiki.ru|     ru.vsepostavshiki|       https|    NULL|     /syre/volgograd|     NULL|2024-06-16 03:23:52|         200|          NULL|FQHYEMDPB5C3DRJOS...|        text/html|            text/html|          UTF-8|              rus|             NULL|crawl-data/CC-MAI...|         567436752|              7849|1718198861640.68|\n",
      "|ru,vsepostavshiki...|https://vsepostav...|vsepostavshiki.ru|          ru|        vsepostavshiki|                  NULL|                  NULL|                  NULL|                      ru|         vsepostavshiki.ru|                     ru|      vsepostavshiki.ru|     ru.vsepostavshiki|       https|    NULL|/syre/vtorichnoe-...|     NULL|2024-06-18 08:55:56|         200|          NULL|2O4O53RXABBX73APU...|        text/html|            text/html|          UTF-8|              rus|             NULL|crawl-data/CC-MAI...|         545647258|             11021|1718198861747.70|\n",
      "|ru,vsepostavshiki...|https://vsepostav...|vsepostavshiki.ru|          ru|        vsepostavshiki|                  NULL|                  NULL|                  NULL|                      ru|         vsepostavshiki.ru|                     ru|      vsepostavshiki.ru|     ru.vsepostavshiki|       https|    NULL|              /tovar|     NULL|2024-06-18 21:15:26|         200|          NULL|QAZLX7HLSJX5C3OAV...|        text/html|            text/html|          UTF-8|              rus|             NULL|crawl-data/CC-MAI...|         537377511|              9228|1718198861794.76|\n",
      "|ru,vsepostavshiki...|https://vsepostav...|vsepostavshiki.ru|          ru|        vsepostavshiki|                  NULL|                  NULL|                  NULL|                      ru|         vsepostavshiki.ru|                     ru|      vsepostavshiki.ru|     ru.vsepostavshiki|       https|    NULL|/tovar/5062-kover...|     NULL|2024-06-20 11:51:07|         200|          NULL|RLVHB6MVQNNXSTPNK...|        text/html|            text/html|          UTF-8|              rus|             NULL|crawl-data/CC-MAI...|         539769264|              9152|1718198861940.83|\n",
      "+--------------------+--------------------+-----------------+------------+----------------------+----------------------+----------------------+----------------------+------------------------+--------------------------+-----------------------+-----------------------+----------------------+------------+--------+--------------------+---------+-------------------+------------+--------------+--------------------+-----------------+---------------------+---------------+-----------------+-----------------+--------------------+------------------+------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/01 08:36:00 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "cc_main_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcb0b11-1c32-49ee-af0c-354f52802f0a",
   "metadata": {},
   "source": [
    "## Creating Iceberg namespace under the catalog\n",
    "We create the namespace (schema) under the iceberg catalog `iceberg_rest` we created in the Spark Session configs, to demarcate the date being saved using the Rest Java catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea8b1cde-adba-4c21-ae75-fc39d4f58e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"create namespace iceberg_rest.java\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4cdb8b-30a1-4f9c-9754-1207b2f2b1d2",
   "metadata": {},
   "source": [
    "## Writing the data to Iceberg Table\n",
    "Finally, writing the data to the Iceberg table and timing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d83affd-ee7c-4689-a44e-7f965b56df17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.386883415005286\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "cc_main_df.writeTo(\"iceberg_rest.java.cc_main_2024_26_part_00000\").create()\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
